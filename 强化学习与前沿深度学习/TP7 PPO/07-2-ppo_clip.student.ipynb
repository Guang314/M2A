{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a730b26f",
   "metadata": {},
   "source": [
    " Copyright © Sorbonne University.\n",
    "\n",
    " This source code is licensed under the MIT license found in the LICENSE file\n",
    " in the root directory of this source tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04297f62",
   "metadata": {},
   "source": [
    "# Outlook\n",
    "\n",
    "In this notebook we code one version of the [Proximal Policy Optimization\n",
    "(PPO)](https://arxiv.org/pdf/1707.06347.pdf) algorithms using BBRL. More\n",
    "precisely, the version here is the one that clips the policy gradient.\n",
    "\n",
    "The PPO algorithm is superficially explained in [this\n",
    "video](https://www.youtube.com/watch?v=uRNL93jV2HE) and you can also read [the\n",
    "corresponding slides](http://pages.isir.upmc.fr/~sigaud/teach/ps/10_ppo.pdf).\n",
    "\n",
    "It is also a good idea to have a look at the [spinning up\n",
    "documentation](https://spinningup.openai.com/en/latest/algorithms/ppo.html).\n",
    "\n",
    "This version of PPO works, but it incorrectly samples minibatches randomly\n",
    "from the rollouts without making sure that each sample is used once and only\n",
    "once See:\n",
    "https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/ for a\n",
    "full description of all the coding tricks that should be integrated\n",
    "\n",
    "# 展望\n",
    "\n",
    "在本笔记中，我们使用BBRL实现了[近端策略优化(PPO)](https://arxiv.org/pdf/1707.06347.pdf)算法的一个版本。具体来说，这里实现的版本使用了策略梯度剪裁技术。\n",
    "\n",
    "PPO算法的基础介绍可以在[这个视频](https://www.youtube.com/watch?v=uRNL93jV2HE)中找到，或者查看[对应的幻灯片](http://pages.isir.upmc.fr/~sigaud/teach/ps/10_ppo.pdf)。\n",
    "\n",
    "也推荐阅读[spinning up文档](https://spinningup.openai.com/en/latest/algorithms/ppo.html)。\n",
    "\n",
    "此PPO版本工作正常，但在从rollouts中随机采样minibatch时没有确保每个样本只使用一次。更多代码技巧请参见[此链接](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971c5d0",
   "metadata": {},
   "source": [
    "# Setting up the environment\n",
    "We first need to setup the environment\n",
    "Installs the necessary Python and system libraries\n",
    "\n",
    "# 设置环境\n",
    "\n",
    "我们首先需要设置环境，安装所需的Python和系统库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40fe186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chen_guanyu/deepdac/lib/python3.10/site-packages/bbrl_utils/notebook.py:46: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm  # noqa: F401\n",
      "error: XDG_RUNTIME_DIR not set in the environment.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from easypip import easyimport\n",
    "except ModuleNotFoundError:\n",
    "    from subprocess import run\n",
    "    assert run([\"pip\", \"install\", \"easypip\"]).returncode == 0, \"Could not install easypip\"\n",
    "    from easypip import easyimport\n",
    "\n",
    "easyimport(\"swig\")\n",
    "easyimport(\"bbrl_utils\").setup()\n",
    "\n",
    "# [[imports]]\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from bbrl.agents import Agent, Agents, KWAgentWrapper, TemporalAgent\n",
    "from bbrl_utils.algorithms import EpisodicAlgo, iter_partial_episodes\n",
    "from bbrl_utils.nn import build_ortho_mlp, setup_optimizer\n",
    "from bbrl_utils.notebook import setup_tensorboard\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from bbrl_utils.nn import copy_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7458008d",
   "metadata": {},
   "source": [
    "# Learning environment\n",
    "\n",
    "## Configuration\n",
    "\n",
    "The learning environment is controlled by a configuration that define a few\n",
    "important things as described in the example below. This configuration can\n",
    "hold as many extra information as you need, the example below is the minimal\n",
    "one.\n",
    "\n",
    "# 学习环境\n",
    "\n",
    "## 配置\n",
    "\n",
    "学习环境通过一个配置进行控制，该配置定义了一些重要的内容，如下面的示例所示。该配置可以包含尽可能多的额外信息，下面的示例是最简化的版本。\n",
    "\n",
    "```python\n",
    "params = {\n",
    "    # This defines the a path for logs and saved models\n",
    "    \"base_dir\": \"${gym_env.env_name}/myalgo_${current_time:}\",\n",
    "\n",
    "    # The Gymnasium environment\n",
    "    \"gym_env\": {\n",
    "        \"env_name\": \"CartPoleContinuous-v1\",\n",
    "    },\n",
    "\n",
    "    # Algorithm\n",
    "    \"algorithm\": {\n",
    "        # Seed used for the random number generator\n",
    "        \"seed\": 1023,\n",
    "\n",
    "        # Number of parallel training environments\n",
    "        \"n_envs\": 8,\n",
    "                \n",
    "        # Minimum number of steps between two evaluations\n",
    "        \"eval_interval\": 500,\n",
    "        \n",
    "        # Number of parallel evaluation environments\n",
    "        \"nb_evals\": 10,\n",
    "\n",
    "        # Number of epochs (loops)\n",
    "        \"max_epochs\": 40000,\n",
    "\n",
    "        # Number of steps (partial iteration)\n",
    "        \"n_steps\": 100,\n",
    "        \n",
    "    },\n",
    "}\n",
    "\n",
    "# Creates the configuration object, i.e. cfg.algorithm.nb_evals is 10\n",
    "cfg = OmegaConf.create(params)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea5577",
   "metadata": {},
   "source": [
    "## The RL algorithm\n",
    "\n",
    "In this notebook, the RL algorithm is based on `EpisodicAlgo`, that defines\n",
    "the algorithm environment when using episodes. To use such environment, we\n",
    "just need to subclass `EpisodicAlgo` and to define two things, namely the\n",
    "`train_policy` and the `eval_policy`. Both are BBRL agents that, given the\n",
    "environment state, select the action to perform.\n",
    "\n",
    "## 强化学习算法\n",
    "\n",
    "在这个笔记本中，强化学习算法基于 `EpisodicAlgo`，该类定义了使用回合时的算法环境。要使用这样的环境，我们只需继承 `EpisodicAlgo` 类，并定义两个内容，即 `train_policy` 和 `eval_policy`。这两者都是 BBRL 代理，根据环境状态选择要执行的动作。\n",
    "\n",
    "```py\n",
    "  class MyAlgo(EpisodicAlgo):\n",
    "      def __init__(self, cfg):\n",
    "          super().__init__(cfg)\n",
    "\n",
    "          # Define the train and evaluation policies\n",
    "          # (the agents compute the workspace `action` variable)\n",
    "          self.train_policy = MyPolicyAgent(...)\n",
    "          self.eval_policy = MyEvalAgent(...)\n",
    "\n",
    "algo = MyAlgo(cfg)\n",
    "```\n",
    "\n",
    "`EpisodicAlgo` 定义了一些有用的对象：\n",
    "\n",
    "- `algo.cfg` 是配置\n",
    "- `algo.nb_steps`（整数）是自训练开始以来的步骤数\n",
    "- `algo.logger` 是一个可以在训练期间收集统计信息的记录器：\n",
    "    - `algo.logger.add_log(\"critic_loss\", critic_loss, algo.nb_steps)` 将 `critic_loss` 值记录到 TensorBoard\n",
    "- `algo.evaluate()` 在需要时评估当前的 `eval_policy`，并保留如果它是迄今为止表现最佳的代理（平均累积奖励）；\n",
    "- `algo.visualize_best()` 在一个回合中运行最佳代理，并显示视频\n",
    "\n",
    "此外，它还定义了 `iter_episodes`，允许对部分回合进行迭代（从 `n_envs` 环境中的 `n_steps`）：\n",
    "\n",
    "```python3\n",
    "  # with partial episodes\n",
    "  for workspace in algo.iter_partial_episodes():\n",
    "      # workspace is a workspace containing 50 transitions\n",
    "      # (with autoreset)\n",
    "      ...\n",
    "```\n",
    "\n",
    "The `EpisodicAlgo` defines useful objects:\n",
    "\n",
    "- `algo.cfg` is the configuration\n",
    "- `algo.nb_steps` (integer) is the number of steps since the training began\n",
    "- `algo.logger` is a logger that can be used to collect statistics during training:\n",
    "    - `algo.logger.add_log(\"critic_loss\", critic_loss, algo.nb_steps)` registers the `critic_loss` value on tensorboard\n",
    "- `algo.evaluate()` evaluates the current `eval_policy` if needed, and keeps the\n",
    "agent if it was the best so far (average cumulated reward);\n",
    "- `algo.visualize_best()` runs the best agent on one episode, and displays the video\n",
    "\n",
    "\n",
    "\n",
    "Besides, it also defines an `iter_episodes` that allows to iterate over partial\n",
    "episodes (with `n_steps` from `n_envs` environments):\n",
    "\n",
    "```python3\n",
    "  # with partial episodes\n",
    "  for workspace in algo.iter_partial_episodes():\n",
    "      # workspace is a workspace containing 50 transitions\n",
    "      # (with autoreset)\n",
    "      ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c9fb4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Definition of PPO agents\n",
    "\n",
    "## Critic agent\n",
    "\n",
    "As A2C, PPO uses a value function $V(s)$. We thus call upon the `VAgent`\n",
    "class,  which takes an observation as input and whose output is the value of\n",
    "this observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c327f",
   "metadata": {},
   "source": [
    "# PPO 代理的定义\n",
    "\n",
    "## 评估代理\n",
    "\n",
    "与 A2C 相似，PPO 使用价值函数 \\(V(s)\\)。因此，我们调用 `VAgent` 类，该类以观察为输入，其输出为该观察的价值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4e38d72",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class VAgent(Agent):\n",
    "    def __init__(self, state_dim, hidden_layers, name=\"critic\"):\n",
    "        super().__init__(name)\n",
    "        self.is_q_function = False\n",
    "        self.model = build_ortho_mlp(\n",
    "            [state_dim] + list(hidden_layers) + [1], activation=nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, t, **kwargs):\n",
    "        observation = self.get((\"env/env_obs\", t))\n",
    "        critic = self.model(observation).squeeze(-1)\n",
    "        self.set((f\"{self.prefix}v_values\", t), critic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa06636",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## The DiscretePolicy\n",
    "\n",
    "The DiscretePolicy was already used in A2C to deal with discrete actions, but\n",
    "we have added the possibility to only predict the probability of an action\n",
    "using the ```predict_proba``` variable in the ```forward()``` function. The\n",
    "code is as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb5cd6",
   "metadata": {},
   "source": [
    "## 离散策略\n",
    "\n",
    "离散策略（DiscretePolicy）在 A2C 中已经用于处理离散动作，但我们增加了一个可能性，可以仅使用 `forward()` 函数中的 `predict_proba` 变量来预测某个动作的概率。代码如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "033f6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscretePolicy(Agent):\n",
    "    def __init__(self, state_dim, hidden_size, n_actions, name=\"policy\"):\n",
    "        super().__init__(name=name)\n",
    "        self.model = build_ortho_mlp(\n",
    "            [state_dim] + list(hidden_size) + [n_actions], activation=nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def dist(self, obs):\n",
    "        scores = self.model(obs)\n",
    "        probs = torch.softmax(scores, dim=-1)\n",
    "        return torch.distributions.Categorical(probs)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        t,\n",
    "        *,\n",
    "        stochastic=True,\n",
    "        predict_proba=False,\n",
    "        compute_entropy=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Compute the action given either a time step (looking into the workspace)\n",
    "        or an observation (in kwargs)\n",
    "        \"\"\"\n",
    "        observation = self.get((\"env/env_obs\", t))\n",
    "        scores = self.model(observation)\n",
    "        probs = torch.softmax(scores, dim=-1)\n",
    "\n",
    "        if predict_proba:\n",
    "            action = self.get((\"action\", t))\n",
    "            log_probs = probs[torch.arange(probs.size()[0]), action].log()\n",
    "            self.set((f\"{self.prefix}logprob_predict\", t), log_probs)\n",
    "        else:\n",
    "            if stochastic:\n",
    "                action = torch.distributions.Categorical(probs).sample()\n",
    "            else:\n",
    "                action = scores.argmax(1)\n",
    "            self.set((\"action\", t), action)\n",
    "\n",
    "        if compute_entropy:\n",
    "            entropy = torch.distributions.Categorical(probs).entropy()\n",
    "            self.set((f\"{self.prefix}entropy\", t), entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60e8f5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Main PPO agent\n",
    "\n",
    "In the following, we create the PPO Agent, with one policy and one critic,\n",
    "and their \"delayed\" versions (target network for the critic, and previous \n",
    "policy in the inner loop of the optimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30cf2fe",
   "metadata": {},
   "source": [
    "### 主要 PPO 代理\n",
    "\n",
    "接下来，我们创建 PPO 代理，包含一个策略和一个评论者，以及它们的“延迟”版本（评论者的目标网络和优化内循环中的先前策略）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e516d38d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class PPOClip(EpisodicAlgo):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__(cfg, autoreset=True)\n",
    "        obs_size, act_size = self.train_env.get_obs_and_actions_sizes()\n",
    "\n",
    "        self.train_policy = globals()[cfg.algorithm.policy_type](\n",
    "            obs_size,\n",
    "            cfg.algorithm.architecture.actor_hidden_size,\n",
    "            act_size,\n",
    "        ).with_prefix(\"current_policy/\")\n",
    "\n",
    "        self.eval_policy = KWAgentWrapper(\n",
    "            self.train_policy, \n",
    "            stochastic=False,\n",
    "            predict_proba=False,\n",
    "            compute_entropy=False,\n",
    "        )\n",
    "\n",
    "        self.critic_agent = VAgent(\n",
    "            obs_size, cfg.algorithm.architecture.critic_hidden_size\n",
    "        ).with_prefix(\"critic/\")\n",
    "        self.old_critic_agent = copy.deepcopy(self.critic_agent).with_prefix(\"old_critic/\")\n",
    "\n",
    "        self.old_policy = copy.deepcopy(self.train_policy)\n",
    "        self.old_policy.with_prefix(\"old_policy/\")\n",
    "\n",
    "        self.policy_optimizer = setup_optimizer(\n",
    "            cfg.optimizer, self.train_policy\n",
    "        )\n",
    "        self.critic_optimizer = setup_optimizer(\n",
    "            cfg.optimizer, self.critic_agent\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b580a5",
   "metadata": {},
   "source": [
    "In the cell below, we optimize the policy loss for PPO-clip, i.e.\n",
    "\n",
    "在下面的单元格中，我们优化 PPO-clip 的策略损失，即\n",
    "\n",
    "$$\n",
    "L^{C L I P}(\\theta)=\\hat{\\mathbb{E}}_t\\left[\\min \\left(r_t(\\theta) \\hat{A}_t, \\operatorname{clip}\\left(r_t(\\theta), 1-\\epsilon, 1+\\epsilon\\right) \\hat{A}_t\\right)\\right]\n",
    "$$\n",
    "where $$r_t(\\theta) = \\frac{\\pi_\\theta\\left(a_t \\mid s_t\\right)}{\\pi_{\\theta_{\\text {old }}}\\left(a_t \\mid s_t\\right)}$$\n",
    "\n",
    "Useful torch functions:\n",
    "- [torch.clamp](https://pytorch.org/docs/stable/generated/torch.clamp.html) computes $\\min(\\max(x_i, m_i), M_i)$ where $m_i$ and $M_i$ are the lower and upper bounds respectively\n",
    "\n",
    "有用的 Torch 函数：\n",
    "- [torch.clamp](https://pytorch.org/docs/stable/generated/torch.clamp.html) 计算 $\\min(\\max(x_i, m_i), M_i)$，其中 $m_i$ 和 $M_i$ 分别是下界和上界。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b7c33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bbrl.utils.functional import gae\n",
    "\n",
    "def run(ppo_clip: PPOClip):\n",
    "    cfg = ppo_clip.cfg\n",
    "\n",
    "    t_policy = TemporalAgent(ppo_clip.train_policy)\n",
    "    t_old_policy = TemporalAgent(ppo_clip.old_policy)\n",
    "    t_critic = TemporalAgent(ppo_clip.critic_agent)\n",
    "    t_old_critic = TemporalAgent(ppo_clip.old_critic_agent)\n",
    "\n",
    "    for train_workspace in iter_partial_episodes(\n",
    "        ppo_clip, cfg.algorithm.n_steps\n",
    "    ):\n",
    "        # Run the current policy and evaluate the proba of its action according\n",
    "        # to the old policy The old_policy can be run after the train_agent on\n",
    "        # the same workspace because it writes a logprob_predict and not an\n",
    "        # action. That is, it does not determine the action of the old_policy,\n",
    "        # it just determines the proba of the action of the current policy given\n",
    "        # its own probabilities\n",
    "\n",
    "        with torch.no_grad():\n",
    "            t_old_policy(\n",
    "                train_workspace,\n",
    "                t=0,\n",
    "                n_steps=cfg.algorithm.n_steps,\n",
    "                # Just computes the probability of the old policy's action\n",
    "                # to get the ratio of probabilities\n",
    "                predict_proba=True,\n",
    "                compute_entropy=False,\n",
    "            )\n",
    "\n",
    "        # Compute the critic value over the whole workspace\n",
    "        t_critic(train_workspace, t=0, n_steps=cfg.algorithm.n_steps)\n",
    "        with torch.no_grad():\n",
    "            t_old_critic(train_workspace, t=0, n_steps=cfg.algorithm.n_steps)\n",
    "\n",
    "        ws_terminated, ws_reward, ws_v_value, ws_old_v_value = train_workspace[\n",
    "            \"env/terminated\",\n",
    "            \"env/reward\",\n",
    "            \"critic/v_values\",\n",
    "            \"old_critic/v_values\",\n",
    "        ]\n",
    "\n",
    "        # the critic values are clamped to move not too far away from the values of the previous critic\n",
    "        if cfg.algorithm.clip_range_vf > 0:\n",
    "            # Clip the difference between old and new values\n",
    "            # NOTE: this depends on the reward scaling\n",
    "            ws_v_value = ws_old_v_value + torch.clamp(\n",
    "                ws_v_value - ws_old_v_value,\n",
    "                -cfg.algorithm.clip_range_vf,\n",
    "                cfg.algorithm.clip_range_vf,\n",
    "            )\n",
    "\n",
    "        # Compute the advantage using the (clamped) critic values\n",
    "        with torch.no_grad():\n",
    "            advantage = gae(\n",
    "                ws_reward[1:],\n",
    "                ws_v_value[1:],\n",
    "                ~ws_terminated[1:],\n",
    "                ws_v_value[:-1],\n",
    "                cfg.algorithm.discount_factor,\n",
    "                cfg.algorithm.gae,\n",
    "            )\n",
    "\n",
    "        ppo_clip.critic_optimizer.zero_grad()\n",
    "        target = ws_reward[1:] + cfg.algorithm.discount_factor * ws_old_v_value[1:].detach() * (1 - ws_terminated[1:].int())\n",
    "        critic_loss = torch.nn.functional.mse_loss(ws_v_value[:-1], target) * cfg.algorithm.critic_coef\n",
    "        critic_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            ppo_clip.critic_agent.parameters(), cfg.algorithm.max_grad_norm\n",
    "        )\n",
    "        ppo_clip.critic_optimizer.step()\n",
    "\n",
    "        # We store the advantage into the transition_workspace\n",
    "        if cfg.algorithm.normalize_advantage and advantage.shape[1] > 1:\n",
    "            advantage = (advantage - advantage.mean()) / (advantage.std() + 1e-8)\n",
    "        train_workspace.set_full(\"advantage\", torch.cat(\n",
    "            (advantage, torch.zeros(1, advantage.shape[1]))\n",
    "        ))\n",
    "        transition_workspace = train_workspace.get_transitions()\n",
    "\n",
    "        # Inner optimization loop: we sample transitions and use them to learn\n",
    "        # the policy\n",
    "        for opt_epoch in range(cfg.algorithm.opt_epochs):\n",
    "            if cfg.algorithm.batch_size > 0:\n",
    "                sample_workspace = transition_workspace.select_batch_n(\n",
    "                    cfg.algorithm.batch_size\n",
    "                )\n",
    "            else:\n",
    "                sample_workspace = transition_workspace\n",
    "\n",
    "            # Compute the policy loss\n",
    "\n",
    "            # Compute the probability of the played actions according to the current policy\n",
    "            # We do not replay the action: we use the one stored into the dataset\n",
    "            # Hence predict_proba=True\n",
    "            # Note that the policy is not wrapped into a TemporalAgent, but we use a single step\n",
    "            ppo_clip.train_policy(\n",
    "                sample_workspace, \n",
    "                t = 0,\n",
    "                n_steps=2,\n",
    "                predict_proba=True,\n",
    "                compute_entropy=True\n",
    "            )\n",
    "\n",
    "            log_prob_current = sample_workspace[\"current_policy/logprob_predict\"]\n",
    "            log_prob_old = sample_workspace[\"old_policy/logprob_predict\"]\n",
    "\n",
    "            # Compute the ratio of action probabilities\n",
    "            ratio = (log_prob_current - log_prob_old).exp()\n",
    "\n",
    "            # Compute the policy loss\n",
    "            # (using cfg.algorithm.clip_range and torch.clamp)\n",
    "            # assert False, 'Not implemented yet'\n",
    "            policy_advantage = sample_workspace[\"advantage\"]\n",
    "            epsilon = cfg.algorithm.clip_range\n",
    "\n",
    "            loss_unclip = policy_advantage * ratio\n",
    "\n",
    "            ratio_clip = torch.clamp(ratio, 1-epsilon, 1+epsilon)\n",
    "            loss_clip = ratio_clip * policy_advantage\n",
    "            \n",
    "            loss_min = torch.min(loss_unclip, loss_clip)\n",
    "            policy_loss = torch.mean(loss_min)\n",
    "\n",
    "            loss_policy = -cfg.algorithm.policy_coef * policy_loss\n",
    "\n",
    "            # Entropy loss favors exploration Note that the standard PPO\n",
    "            entropy = sample_workspace[\"current_policy/entropy\"]\n",
    "            entropy = torch.mean(entropy, dim=0, keepdim=True)\n",
    "            \n",
    "            # algorithms do not have an entropy term, they don't need it because\n",
    "            # the KL term is supposed to deal with exploration So, to run the\n",
    "            # standard PPO algorithm, you should set\n",
    "            # cfg.algorithm.entropy_coef=0\n",
    "            assert len(entropy) == 1, f\"{entropy.shape}\"\n",
    "            entropy_loss = entropy[0].mean()\n",
    "            loss_entropy = -cfg.algorithm.entropy_coef * entropy_loss\n",
    "\n",
    "            # Store the losses for tensorboard display\n",
    "            ppo_clip.logger.log_losses(\n",
    "                critic_loss, entropy_loss, policy_loss, ppo_clip.nb_steps\n",
    "            )\n",
    "            ppo_clip.logger.add_log(\n",
    "                \"advantage\", policy_advantage[0].mean(), ppo_clip.nb_steps\n",
    "            )\n",
    "\n",
    "            loss = loss_policy + loss_entropy\n",
    "\n",
    "            ppo_clip.policy_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                ppo_clip.train_policy.parameters(), cfg.algorithm.max_grad_norm\n",
    "            )\n",
    "            ppo_clip.policy_optimizer.step()\n",
    "\n",
    "        # Copy parameters\n",
    "        copy_parameters(ppo_clip.train_policy, ppo_clip.old_policy)\n",
    "        copy_parameters(ppo_clip.critic_agent, ppo_clip.old_critic_agent)\n",
    "\n",
    "        # Evaluates our current algorithm if needed\n",
    "        ppo_clip.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f3e33",
   "metadata": {},
   "source": [
    "# Definition of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fcda063",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"base_dir\": \"${gym_env.env_name}/ppo-clip-S${algorithm.seed}_${current_time:}\",\n",
    "    \"save_best\": False,\n",
    "    \"logger\": {\n",
    "        \"classname\": \"bbrl.utils.logger.TFLogger\",\n",
    "        \"cache_size\": 10000,\n",
    "        \"every_n_seconds\": 10,\n",
    "        \"verbose\": False,\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"seed\": 12,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "        \"n_envs\": 8,\n",
    "        \"n_steps\": 32,\n",
    "        \"eval_interval\": 1000,\n",
    "        \"nb_evals\": 10,\n",
    "        \"gae\": 0.8,\n",
    "        \"discount_factor\": 0.98,\n",
    "        \"normalize_advantage\": False,\n",
    "        \"max_epochs\": 5_000,\n",
    "        \"opt_epochs\": 10,\n",
    "        \"batch_size\": 256,\n",
    "        \"clip_range\": 0.2,\n",
    "        \"clip_range_vf\": 0,\n",
    "        \"entropy_coef\": 2e-7,\n",
    "        \"policy_coef\": 1,\n",
    "        \"critic_coef\": 1.0,\n",
    "        \"policy_type\": \"DiscretePolicy\",\n",
    "        \"architecture\": {\n",
    "            \"actor_hidden_size\": [64, 64],\n",
    "            \"critic_hidden_size\": [64, 64],\n",
    "        },\n",
    "    },\n",
    "    \"gym_env\": {\n",
    "        \"env_name\": \"CartPole-v1\",\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"classname\": \"torch.optim.AdamW\",\n",
    "        \"lr\": 1e-3,\n",
    "        \"eps\": 1e-5,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611a932",
   "metadata": {},
   "source": [
    "## Launching tensorboard to visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebbedfe4",
   "metadata": {
    "title": "For Colab - otherwise, it is easier and better to launch tensorboard from"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launch tensorboard from the shell: \n",
      "/home/chen_guanyu/deepdac/bin/tensorboard --logdir '/home/chen_guanyu/M2A/M2A_RLD/TP7 PPO/outputs'\n"
     ]
    }
   ],
   "source": [
    "# the terminal\n",
    "\n",
    "setup_tensorboard(\"./outputs/tblogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11e1e83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 13:27:06.841905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-28 13:27:06.972170: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-28 13:27:07.008169: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-28 13:27:07.271276: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorboard/compat/__init__.py:42\u001b[0m, in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notf  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/home/chen_guanyu/deepdac/lib/python3.10/site-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m Version\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m tensorboard\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileWriter, SummaryWriter  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecord_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecordWriter  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_file_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EventFileWriter\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_convert_np\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_np\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_embedding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_onnx_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_onnx_graph\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytorch_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/torch/utils/tensorboard/_embedding.py:10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojector_config_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingInfo\n\u001b[0;32m---> 10\u001b[0m _HAS_GFILE_JOIN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241m.\u001b[39mgfile, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gfile_join\u001b[39m(a, b):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# The join API is different between tensorboard's TF stub and TF:\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# https://github.com/tensorflow/tensorboard/issues/6080\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# We need to try both because `tf` may point to either the stub or the real TF.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _HAS_GFILE_JOIN:\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorboard/lazy.py:65\u001b[0m, in \u001b[0;36mlazy_load.<locals>.wrapper.<locals>.LazyModule.__getattr__\u001b[0;34m(self, attr_name)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr_name):\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43mload_once\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m, attr_name)\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorboard/lazy.py:97\u001b[0m, in \u001b[0;36m_memoize.<locals>.wrapper\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m cache\u001b[38;5;241m.\u001b[39mget(arg, nothing) \u001b[38;5;129;01mis\u001b[39;00m nothing:\n\u001b[0;32m---> 97\u001b[0m             cache[arg] \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cache[arg]\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorboard/lazy.py:50\u001b[0m, in \u001b[0;36mlazy_load.<locals>.wrapper.<locals>.load_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m load_once\u001b[38;5;241m.\u001b[39mloading \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mload_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     load_once\u001b[38;5;241m.\u001b[39mloading \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorboard/compat/__init__.py:45\u001b[0m, in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tensorflow\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/__init__.py:47\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     45\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute.combinations namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m env \u001b[38;5;66;03m# line: 456\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate \u001b[38;5;66;03m# line: 365\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_main_process \u001b[38;5;66;03m# line: 418\u001b[39;00m\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/python/distribute/combinations.py:33\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m session\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_all_reduce_strategy\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow_server_pb2\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_ops \u001b[38;5;28;01mas\u001b[39;00m cross_device_ops_lib\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/python/distribute/cross_device_ops.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_lib\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_utils\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/python/distribute/cross_device_utils.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, List, Optional, Union\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m values \u001b[38;5;28;01mas\u001b[39;00m value_lib\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backprop_util\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/python/distribute/values.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m struct_pb2\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m packed_distributed_variable \u001b[38;5;28;01mas\u001b[39;00m packed\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reduce_util\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:205\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_ctx \u001b[38;5;28;01mas\u001b[39;00m autograph_ctx\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m autograph\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_ops\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/python/data/__init__.py:21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/python/data/experimental/__init__.py:98\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/python/data/experimental/service/__init__.py:419\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils_exp\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_ops\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m options \u001b[38;5;28;01mas\u001b[39;00m options_lib\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structured_function\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_autograph\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m debug_mode\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m iterator_ops\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m options \u001b[38;5;28;01mas\u001b[39;00m options_lib\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structured_function\n",
      "File \u001b[0;32m~/deepdac/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saveable_compat\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m iterator_autograph\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optional_ops\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m options \u001b[38;5;28;01mas\u001b[39;00m options_lib\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7827bfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b9f9d7d7f0468895126d272f7f29f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppo_clip = PPOClip(OmegaConf.create(params))\n",
    "run(ppo_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "310d1ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video of best agent recorded in outputs/CartPole-v1/ppo-clip-S12_20241022-212233/best_agent.mp4\n",
      "Moviepy - Building video /home/chen_guanyu/M2A/M2A_RLD/outputs/CartPole-v1/ppo-clip-S12_20241022-212233/best_agent.mp4.\n",
      "Moviepy - Writing video /home/chen_guanyu/M2A/M2A_RLD/outputs/CartPole-v1/ppo-clip-S12_20241022-212233/best_agent.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/chen_guanyu/M2A/M2A_RLD/outputs/CartPole-v1/ppo-clip-S12_20241022-212233/best_agent.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div align=middle><video src='data:video/mp4;base64,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' controls>Sorry, seems like your browser doesn't support HTML5 audio/video</video></div>"
      ],
      "text/plain": [
       "<moviepy.video.io.html_tools.HTML2 object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_clip.visualize_best()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\""
  },
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
