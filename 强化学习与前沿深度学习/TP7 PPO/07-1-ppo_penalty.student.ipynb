{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f68ee6d0",
   "metadata": {},
   "source": [
    " Copyright © Sorbonne University.\n",
    "\n",
    " This source code is licensed under the MIT license found in the LICENSE file\n",
    " in the root directory of this source tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1396b5",
   "metadata": {},
   "source": [
    "# Outlook\n",
    "\n",
    "In this notebook we code one version of the [Proximal Policy Optimization\n",
    "(PPO)](https://arxiv.org/pdf/1707.06347.pdf) algorithms using BBRL. More\n",
    "precisely, the version here is the one that uses the KL penalty as a\n",
    "regularization term when optimizing the policy gradient.\n",
    "\n",
    "The PPO algorithm is superficially explained in [this\n",
    "video](https://www.youtube.com/watch?v=uRNL93jV2HE) and you can also read [the\n",
    "corresponding slides](http://pages.isir.upmc.fr/~sigaud/teach/ps/10_ppo.pdf).\n",
    "\n",
    "It is also a good idea to have a look at the [spinning up\n",
    "documentation](https://spinningup.openai.com/en/latest/algorithms/ppo.html).\n",
    "\n",
    "This version of PPO works, but it incorrectly samples minibatches randomly\n",
    "from the rollouts without making sure that each sample is used once and only\n",
    "once See:\n",
    "https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/ for a\n",
    "full description of all the coding tricks that should be integrated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df2ef01",
   "metadata": {},
   "source": [
    "# 展望\n",
    "\n",
    "在这个笔记本中，我们使用 BBRL 编写了 [Proximal Policy Optimization (PPO)](https://arxiv.org/pdf/1707.06347.pdf) 算法的一个版本。具体来说，这个版本在优化策略梯度时使用 KL 惩罚作为正则项。\n",
    "\n",
    "可以通过 [这个视频](https://www.youtube.com/watch?v=uRNL93jV2HE) 了解 PPO 算法的简介，并阅读 [对应的幻灯片](http://pages.isir.upmc.fr/~sigaud/teach/ps/10_ppo.pdf)。\n",
    "\n",
    "还建议查看 [spinning up 文档](https://spinningup.openai.com/en/latest/algorithms/ppo.html) 。\n",
    "\n",
    "这个 PPO 版本有效，但在从回合中随机抽取小批量样本时存在缺陷，详见 [文章](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a514da8c",
   "metadata": {},
   "source": [
    "# Setting up the environment\n",
    "We first need to setup the environment\n",
    "Installs the necessary Python and system libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b66597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chen_guanyu/deepdac/lib/python3.10/site-packages/bbrl_utils/notebook.py:46: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm  # noqa: F401\n",
      "error: XDG_RUNTIME_DIR not set in the environment.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from easypip import easyimport\n",
    "except ModuleNotFoundError:\n",
    "    from subprocess import run\n",
    "    assert run([\"pip\", \"install\", \"easypip\"]).returncode == 0, \"Could not install easypip\"\n",
    "    from easypip import easyimport\n",
    "\n",
    "easyimport(\"swig\")\n",
    "easyimport(\"bbrl_utils\").setup()\n",
    "\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from bbrl.agents import Agent, Agents, KWAgentWrapper, TemporalAgent\n",
    "from bbrl_utils.algorithms import EpisodicAlgo, iter_partial_episodes\n",
    "from bbrl_utils.nn import build_ortho_mlp, setup_optimizer\n",
    "from bbrl_utils.notebook import setup_tensorboard\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from bbrl_utils.nn import copy_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd37cf",
   "metadata": {},
   "source": [
    "# Learning environment\n",
    "\n",
    "## Configuration\n",
    "\n",
    "The learning environment is controlled by a configuration that define a few\n",
    "important things as described in the example below. This configuration can\n",
    "hold as many extra information as you need, the example below is the minimal\n",
    "one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28db3fe",
   "metadata": {},
   "source": [
    "# 学习环境\n",
    "\n",
    "## 配置\n",
    "\n",
    "学习环境由一个配置文件控制，该文件定义了一些重要的元素，如以下示例所示。该配置可以包含所需的任意额外信息，下面的示例展示了最小配置。\n",
    "\n",
    "```python\n",
    "params = {\n",
    "    # This defines the a path for logs and saved models\n",
    "    \"base_dir\": \"${gym_env.env_name}/myalgo_${current_time:}\",\n",
    "\n",
    "    # The Gymnasium environment\n",
    "    \"gym_env\": {\n",
    "        \"env_name\": \"CartPoleContinuous-v1\",\n",
    "    },\n",
    "\n",
    "    # Algorithm\n",
    "    \"algorithm\": {\n",
    "        # Seed used for the random number generator\n",
    "        \"seed\": 1023,\n",
    "\n",
    "        # Number of parallel training environments\n",
    "        \"n_envs\": 8,\n",
    "                \n",
    "        # Minimum number of steps between two evaluations\n",
    "        \"eval_interval\": 500,\n",
    "        \n",
    "        # Number of parallel evaluation environments\n",
    "        \"nb_evals\": 10,\n",
    "\n",
    "        # Number of epochs (loops)\n",
    "        \"max_epochs\": 40000,\n",
    "\n",
    "        # Number of steps (partial iteration)\n",
    "        \"n_steps\": 100,\n",
    "        \n",
    "    },\n",
    "}\n",
    "\n",
    "# Creates the configuration object, i.e. cfg.algorithm.nb_evals is 10\n",
    "cfg = OmegaConf.create(params)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949c44c",
   "metadata": {},
   "source": [
    "## The RL algorithm\n",
    "\n",
    "In this notebook, the RL algorithm is based on `EpisodicAlgo`, that defines\n",
    "the algorithm environment when using episodes. To use such environment, we\n",
    "just need to subclass `EpisodicAlgo` and to define two things, namely the\n",
    "`train_policy` and the `eval_policy`. Both are BBRL agents that, given the\n",
    "environment state, select the action to perform.\n",
    "\n",
    "## 强化学习算法\n",
    "\n",
    "在此笔记本中，强化学习算法基于 `EpisodicAlgo`，它定义了在使用回合时的算法环境。要使用这种环境，我们只需继承 `EpisodicAlgo` 并定义两个部分，即 `train_policy` 和 `eval_policy`。这两个部分都是 BBRL 代理，基于环境的状态选择要执行的动作。\n",
    "\n",
    "```py\n",
    "  class MyAlgo(EpisodicAlgo):\n",
    "      def __init__(self, cfg):\n",
    "          super().__init__(cfg)\n",
    "\n",
    "          # Define the train and evaluation policies\n",
    "          # (the agents compute the workspace `action` variable)\n",
    "          self.train_policy = MyPolicyAgent(...)\n",
    "          self.eval_policy = MyEvalAgent(...)\n",
    "\n",
    "algo = MyAlgo(cfg)\n",
    "```\n",
    "\n",
    "The `EpisodicAlgo` defines useful objects:\n",
    "\n",
    "- `algo.cfg` is the configuration\n",
    "- `algo.nb_steps` (integer) is the number of steps since the training began\n",
    "- `algo.logger` is a logger that can be used to collect statistics during training:\n",
    "    - `algo.logger.add_log(\"critic_loss\", critic_loss, algo.nb_steps)` registers the `critic_loss` value on tensorboard\n",
    "- `algo.evaluate()` evaluates the current `eval_policy` if needed, and keeps the\n",
    "agent if it was the best so far (average cumulated reward);\n",
    "- `algo.visualize_best()` runs the best agent on one episode, and displays the video\n",
    "\n",
    "\n",
    "\n",
    "Besides, it also defines an `iter_episodes` that allows to iterate over partial\n",
    "episodes (with `n_steps` from `n_envs` environments):\n",
    "\n",
    "\n",
    "```python3\n",
    "  # with partial episodes\n",
    "  for workspace in algo.iter_partial_episodes():\n",
    "      # workspace is a workspace containing 50 transitions\n",
    "      # (with autoreset)\n",
    "      ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82c861",
   "metadata": {},
   "source": [
    "`EpisodicAlgo` 定义了一些有用的对象：\n",
    "\n",
    "- `algo.cfg`: 配置文件。\n",
    "- `algo.nb_steps` (整数): 表示训练开始以来的步数。\n",
    "- `algo.logger`: 日志记录器，用于在训练过程中收集统计数据，例如 `algo.logger.add_log(\"critic_loss\", critic_loss, algo.nb_steps)` 用于将 `critic_loss` 值记录到 tensorboard。\n",
    "- `algo.evaluate()`: 如有需要，评估当前的 `eval_policy`，并保存表现最佳的代理（根据平均累积奖励）。\n",
    "- `algo.visualize_best()`: 在一回合中运行最佳代理并显示视频。\n",
    "\n",
    "此外，还定义了一个 `iter_episodes`，允许在部分回合中迭代（基于 `n_steps` 和 `n_envs`）。\n",
    "\n",
    "```python3\n",
    "  # with partial episodes\n",
    "  for workspace in algo.iter_partial_episodes():\n",
    "      # workspace is a workspace containing 50 transitions\n",
    "      # (with autoreset)\n",
    "      ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618daa51",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Definition of PPO agents\n",
    "\n",
    "### Critic agent\n",
    "\n",
    "As A2C, PPO uses a value function $V(s)$. We thus call upon the `VAgent`\n",
    "class,  which takes an observation as input and whose output is the value of\n",
    "this observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8068bf51",
   "metadata": {},
   "source": [
    "## 定义PPO代理\n",
    "\n",
    "### 价值网络代理（Critic agent）\n",
    "\n",
    "和A2C算法一样，PPO使用一个值函数 $V(s)$。因此，我们使用`VAgent`类，它以观察值为输入，并输出该观察值对应的价值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a611fc6e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class VAgent(Agent):\n",
    "    def __init__(self, state_dim, hidden_layers, name=\"critic\"):\n",
    "        super().__init__(name=name)\n",
    "        self.is_q_function = False\n",
    "        self.model = build_ortho_mlp(\n",
    "            [state_dim] + list(hidden_layers) + [1], activation=nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, t, **kwargs):\n",
    "        observation = self.get((\"env/env_obs\", t))\n",
    "        critic = self.model(observation).squeeze(-1)\n",
    "        self.set((f\"{self.prefix}v_values\", t), critic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b0cad",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### KL penalty agent\n",
    "\n",
    "When computing the KL penalty, we need to compute the KL divergence at every\n",
    "time step. The KLAgent is specific to the KL regularization version of PPO. It\n",
    "is used to compute the KL divergence between the current and the past policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d6d34",
   "metadata": {},
   "source": [
    "### KL惩罚代理\n",
    "\n",
    "在计算KL惩罚时，我们需要在每个时间步计算KL散度。`KLAgent`是PPO中KL正则化版本的特定代理，用于计算当前策略与过去策略之间的KL散度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9849b2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class KLAgent(Agent):\n",
    "    def __init__(self, model_1, model_2):\n",
    "        super().__init__()\n",
    "        self.model_1 = model_1\n",
    "        self.model_2 = model_2\n",
    "\n",
    "    def forward(self, t, **kwargs):\n",
    "        obs = self.get((\"env/env_obs\", t))\n",
    "        dist_1 = self.model_1.dist(obs)\n",
    "        dist_2 = self.model_2.dist(obs)\n",
    "        kl = torch.distributions.kl.kl_divergence(dist_1, dist_2)\n",
    "        self.set((\"kl\", t), kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fab23b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### The DiscretePolicy\n",
    "\n",
    "The DiscretePolicy was already used in A2C to deal with discrete actions, but\n",
    "we have added the possibility to only predict the probability of an action\n",
    "using the ```predict_proba``` variable in the ```forward()``` function. The\n",
    "code is as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df96d9dd",
   "metadata": {},
   "source": [
    "### DiscretePolicy\n",
    "\n",
    "`DiscretePolicy`之前已用于A2C以处理离散动作，但我们在此基础上增加了仅预测动作概率的功能。通过在`forward()`函数中使用`predict_proba`变量，可以实现这个功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e8b7c3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class DiscretePolicy(Agent):\n",
    "    def __init__(self, state_dim, hidden_size, n_actions, name=\"policy\"):\n",
    "        super().__init__(name=name)\n",
    "        self.model = build_ortho_mlp(\n",
    "            [state_dim] + list(hidden_size) + [n_actions], activation=nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def dist(self, obs):\n",
    "        scores = self.model(obs)\n",
    "        probs = torch.softmax(scores, dim=-1)\n",
    "        return torch.distributions.Categorical(probs)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        t,\n",
    "        *,\n",
    "        stochastic=True,\n",
    "        predict_proba=False,\n",
    "        compute_entropy=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Compute the action given either a time step (looking into the workspace)\n",
    "        or an observation (in kwargs)\n",
    "        \"\"\"\n",
    "        observation = self.get((\"env/env_obs\", t))\n",
    "        scores = self.model(observation)\n",
    "        probs = torch.softmax(scores, dim=-1)\n",
    "        #print(probs)\n",
    "\n",
    "        if predict_proba:\n",
    "            action = self.get((\"action\", t))\n",
    "            log_probs = probs[torch.arange(probs.size()[0]), action].log()\n",
    "            self.set((f\"{self.prefix}logprob_predict\", t), log_probs)\n",
    "        else:\n",
    "            if stochastic:\n",
    "                action = torch.distributions.Categorical(probs).sample()\n",
    "            else:\n",
    "                action = scores.argmax(1)\n",
    "\n",
    "            self.set((\"action\", t), action)\n",
    "\n",
    "        if compute_entropy:\n",
    "            entropy = torch.distributions.Categorical(probs).entropy()\n",
    "            self.set((f\"{self.prefix}entropy\", t), entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac218a26",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Main PPO agent\n",
    "\n",
    "In the following, we create the PPO Agent, with one policy and one critic,\n",
    "and their \"delayed\" versions (target network for the critic, and previous \n",
    "policy in the inner loop of the optimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962645a3",
   "metadata": {},
   "source": [
    "### 主 PPO 代理\n",
    "\n",
    "接下来，我们将创建主 PPO 代理，包含一个策略和一个价值函数（critic），以及它们的“延迟”版本（延迟网络，用于critic的目标网络和优化内部循环中的旧策略）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e102758",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class PPOPenalty(EpisodicAlgo):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__(cfg, autoreset=True)\n",
    "\n",
    "        obs_size, act_size = self.train_env.get_obs_and_actions_sizes()\n",
    "        self.train_policy = globals()[cfg.algorithm.policy_type](\n",
    "            obs_size,\n",
    "            cfg.algorithm.architecture.actor_hidden_size,\n",
    "            act_size,\n",
    "        ).with_prefix(\"current_policy/\")\n",
    "        self.eval_policy = KWAgentWrapper(\n",
    "            self.train_policy, \n",
    "            stochastic=False,\n",
    "            predict_proba=False,\n",
    "            compute_entropy=False,\n",
    "        )\n",
    "\n",
    "        self.critic_agent = VAgent(\n",
    "            obs_size, cfg.algorithm.architecture.critic_hidden_size\n",
    "        ).with_prefix(\"critic/\")\n",
    "        self.old_critic_agent = copy.deepcopy(self.critic_agent).with_prefix(\"old_critic/\")\n",
    "        self.t_all_critics = TemporalAgent(\n",
    "            Agents(self.critic_agent, self.old_critic_agent)\n",
    "        )\n",
    "\n",
    "        self.old_policy = copy.deepcopy(self.train_policy)\n",
    "        self.old_policy.with_prefix(\"old_policy/\")\n",
    "        \n",
    "        self.t_kl_agent = TemporalAgent(KLAgent(self.old_policy, self.train_policy))\n",
    "\n",
    "        self.policy_optimizer = setup_optimizer(\n",
    "            cfg.optimizer, self.train_policy\n",
    "        )\n",
    "        self.critic_optimizer = setup_optimizer(\n",
    "            cfg.optimizer, self.critic_agent\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b23f1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Main PPO loop\n",
    "\n",
    "In the cell below, we optimize the policy loss for PPO-KL, i.e.\n",
    "\n",
    "### 主 PPO 循环\n",
    "\n",
    "在下面的单元中，我们针对PPO-KL优化策略损失，即\n",
    "\n",
    "$$\n",
    "\\max_{\\theta} \\hat{\\mathbb{E}} _t\\left[\\frac{\\pi_\\theta\\left(a_t \\mid s_t\\right)}{\\pi_{\\theta_{\\text {old }}}\\left(a_t \\mid s_t\\right)} \\hat{A}_t-\\beta \\operatorname{KL}\\left[\\pi_{\\theta_{\\text {old }}}\\left(\\cdot \\mid s_t\\right), \\pi_\\theta\\left(\\cdot \\mid s_t\\right)\\right]\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30dd79ff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from bbrl.utils.functional import gae\n",
    "\n",
    "\n",
    "def run_ppo_penalty(ppo: PPOPenalty):\n",
    "    cfg = ppo.cfg\n",
    "\n",
    "    # The old_policy params must be wrapped into a TemporalAgent\n",
    "    t_old_policy = TemporalAgent(ppo.old_policy)\n",
    "\n",
    "    # Training loop\n",
    "    for train_workspace in ppo.iter_partial_episodes():\n",
    "        # Run the current policy and evaluate the proba of its action according\n",
    "        # to the old policy The old_policy can be run after the train_agent on\n",
    "        # the same workspace because it writes a logprob_predict and not an\n",
    "        # action. That is, it does not determine the action of the old_policy,\n",
    "        # it just determines the proba of the action of the current policy given\n",
    "        # its own probabilities\n",
    "\n",
    "        # Compute the critic value over the whole workspace\n",
    "        ppo.t_all_critics(train_workspace, t=0, n_steps=cfg.algorithm.n_steps)\n",
    "\n",
    "        ws_terminated, ws_reward, ws_v_value, ws_old_v_value = train_workspace[\n",
    "            \"env/terminated\",\n",
    "            \"env/reward\",\n",
    "            \"critic/v_values\",\n",
    "            \"old_critic/v_values\",\n",
    "        ]\n",
    "\n",
    "        # --- Critic optimization\n",
    "\n",
    "        # Avoids to extreme V-values (helps stability)\n",
    "        if cfg.algorithm.clip_range_vf > 0:\n",
    "            # Clip the difference between old and new values\n",
    "            # NOTE: this depends on the reward scaling\n",
    "            ws_v_value = ws_old_v_value + torch.clamp(\n",
    "                ws_v_value - ws_old_v_value,\n",
    "                -cfg.algorithm.clip_range_vf,\n",
    "                cfg.algorithm.clip_range_vf,\n",
    "            )\n",
    "\n",
    "        # Compute the advantage using the (clamped) critic values\n",
    "        with torch.no_grad():\n",
    "            advantage = gae(\n",
    "                ws_reward[1:],\n",
    "                ws_v_value[1:],\n",
    "                ~ws_terminated[1:],\n",
    "                ws_v_value[:-1],\n",
    "                cfg.algorithm.discount_factor,\n",
    "                cfg.algorithm.gae,\n",
    "            )\n",
    "        \n",
    "        # Compute the critic loss with TD(0)\n",
    "        target = ws_reward[1:] + cfg.algorithm.discount_factor * ws_old_v_value[1:].detach() * (1 - ws_terminated[1:].int())\n",
    "        critic_loss = torch.nn.functional.mse_loss(ws_v_value[:-1], target) * cfg.algorithm.critic_coef\n",
    "        ppo.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            ppo.critic_agent.parameters(), cfg.algorithm.max_grad_norm\n",
    "        )\n",
    "        ppo.critic_optimizer.step()\n",
    "        \n",
    "        # --- Policy optimization\n",
    "\n",
    "        # We store the advantage into the train_workspace\n",
    "        if cfg.algorithm.normalize_advantage and advantage.shape[1] > 1:\n",
    "            advantage = (advantage - advantage.mean()) / (advantage.std() + 1e-8)\n",
    "        train_workspace.set_full(\"advantage\", torch.cat(\n",
    "            (advantage, torch.zeros(1, advantage.shape[1]))\n",
    "        ))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Just computes the probability of the old policy's action\n",
    "            # to get the ratio of probabilities\n",
    "            t_old_policy(\n",
    "                train_workspace,\n",
    "                t=0,\n",
    "                n_steps=cfg.algorithm.n_steps,\n",
    "                predict_proba=True,\n",
    "                compute_entropy=False,\n",
    "            )\n",
    "\n",
    "        transition_workspace = train_workspace.get_transitions()\n",
    "        for opt_epoch in range(cfg.algorithm.opt_epochs):\n",
    "            if cfg.algorithm.batch_size > 0:\n",
    "                sample_workspace = transition_workspace.select_batch_n(\n",
    "                    cfg.algorithm.batch_size\n",
    "                )\n",
    "            else:\n",
    "                sample_workspace = transition_workspace\n",
    "            \n",
    "            # Compute the policy loss\n",
    "\n",
    "            # Compute the KL divergence\n",
    "\n",
    "            # 使用 KLAgent 计算 KL 散度\n",
    "            ppo.t_kl_agent(sample_workspace,t=0,n_steps=2) \n",
    "            # 从 workspace 中提取 KL 散度\n",
    "            kl = sample_workspace[\"kl\"]\n",
    "\n",
    "            # Compute the probability of the played actions according to the current policy\n",
    "            # 计算当前策略的动作概率\n",
    "            \"\"\" t_current_policy = TemporalAgent(ppo.train_policy)\n",
    "            t_current_policy(\n",
    "                sample_workspace,\n",
    "                t=0,\n",
    "                n_steps=2,\n",
    "                predict_proba=True,\n",
    "                compute_entropy=True\n",
    "            ) \"\"\"\n",
    "            ppo.train_policy(\n",
    "                sample_workspace,\n",
    "                t=0,\n",
    "                n_steps=2,\n",
    "                predict_proba=True,\n",
    "                compute_entropy=True\n",
    "            )\n",
    "\n",
    "            log_prob_current = sample_workspace[\"current_policy/logprob_predict\"]\n",
    "\n",
    "            # We do not replay the action: we use the one stored into the dataset\n",
    "            # Note that the policy is not wrapped into a TemporalAgent, but we use a single step\n",
    "            # 获取旧策略的动作概率\n",
    "            log_prob_old = sample_workspace[\"old_policy/logprob_predict\"]\n",
    "\n",
    "            # Compute the ratio of action probabilities\n",
    "            ratio = (log_prob_current - log_prob_old).exp()\n",
    "            \n",
    "            # Compute the policy loss\n",
    "            # assert False, 'Not implemented yet'\n",
    "            # 计算 PPO 策略损失\n",
    "            policy_advantage = sample_workspace[\"advantage\"]\n",
    "            beta = cfg.algorithm.beta\n",
    "            policy_loss = torch.mean(ratio * policy_advantage - beta * kl)\n",
    "\n",
    "            loss_policy = -cfg.algorithm.policy_coef * policy_loss\n",
    "\n",
    "            # Entropy loss favors exploration\n",
    "            entropy = sample_workspace[\"current_policy/entropy\"]\n",
    "            entropy = torch.mean(entropy, dim=0, keepdim=True)\n",
    "            \n",
    "            # Note that the standard PPO algorithms do not have an entropy term, they don't need it\n",
    "            # because the KL term is supposed to deal with exploration\n",
    "            # So, to run the standard PPO algorithm, you should set cfg.algorithm.entropy_coef=0\n",
    "            assert len(entropy) == 1, f\"{entropy.shape}\"\n",
    "            entropy_loss = entropy[0].mean()\n",
    "            loss_entropy = -cfg.algorithm.entropy_coef * entropy_loss\n",
    "\n",
    "            # Store the losses for tensorboard display\n",
    "            ppo.logger.log_losses(critic_loss, entropy_loss, policy_loss, ppo.nb_steps)\n",
    "            ppo.logger.add_log(\"advantage\", policy_advantage.mean(), ppo.nb_steps)\n",
    "\n",
    "            ppo.policy_optimizer.zero_grad()\n",
    "            loss = loss_policy + loss_entropy\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                ppo.train_policy.parameters(), cfg.algorithm.max_grad_norm\n",
    "            )\n",
    "            ppo.policy_optimizer.step()\n",
    "\n",
    "        # Copy parameters\n",
    "        copy_parameters(ppo.train_policy, ppo.old_policy)\n",
    "        copy_parameters(ppo.critic_agent, ppo.old_critic_agent)\n",
    "        \n",
    "        # Evaluate\n",
    "        ppo.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020ce760",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Definition of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a67cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"base_dir\": \"${gym_env.env_name}/ppo-kl-S${algorithm.seed}-b${algorithm.beta}_${current_time:}\",\n",
    "    \"save_best\": False,\n",
    "    \"algorithm\": {\n",
    "        \"seed\": 12,\n",
    "        \"n_envs\": 8,\n",
    "        \"n_steps\": 32,\n",
    "        \"normalize_advantage\": False,\n",
    "        \"eval_interval\": 1000,\n",
    "        \"nb_evals\": 10,\n",
    "        \"gae\": 0.8,\n",
    "        \"discount_factor\": 0.98,\n",
    "        \"opt_epochs\": 10,\n",
    "        \"batch_size\": 256,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "        \"policy_coef\": 1.,\n",
    "        \"beta\": 5.0,\n",
    "        \"clip_range_vf\": 0,\n",
    "        \"entropy_coef\": 2e-7,\n",
    "        \"critic_coef\": 1.0,\n",
    "        \"policy_type\": \"DiscretePolicy\",\n",
    "        \"architecture\": {\n",
    "            \"actor_hidden_size\": [64, 64],\n",
    "            \"critic_hidden_size\": [64, 64],\n",
    "        },\n",
    "        \"max_epochs\": 5000,\n",
    "    },\n",
    "    \"gym_env\": {\n",
    "        \"env_name\": \"CartPole-v1\",\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"classname\": \"torch.optim.Adam\",\n",
    "        \"lr\": 1e-3,\n",
    "        \"eps\": 1e-5,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bcebca",
   "metadata": {},
   "source": [
    "### Launching tensorboard to visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "957ad00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 752), started 22 days, 3:30:11 ago. (Use '!kill 752' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4dcd8f9ef419c7a0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4dcd8f9ef419c7a0\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setup_tensorboard(\"./outputs/tblogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a85c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 20:51:48.508065: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-22 20:51:48.559228: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-22 20:51:48.573950: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-22 20:51:48.682962: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-22 20:51:49.918838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19aefb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25584896bc84d2ead5cabef37813254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = OmegaConf.create(params)\n",
    "ppo_kl = PPOPenalty(cfg)\n",
    "run_ppo_penalty(ppo_kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b927329c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video of best agent recorded in outputs/CartPole-v1/ppo-kl-S12-b5.0_20241022-205151/best_agent.mp4\n",
      "Moviepy - Building video /home/chen_guanyu/M2A/M2A_RLD/outputs/CartPole-v1/ppo-kl-S12-b5.0_20241022-205151/best_agent.mp4.\n",
      "Moviepy - Writing video /home/chen_guanyu/M2A/M2A_RLD/outputs/CartPole-v1/ppo-kl-S12-b5.0_20241022-205151/best_agent.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/chen_guanyu/M2A/M2A_RLD/outputs/CartPole-v1/ppo-kl-S12-b5.0_20241022-205151/best_agent.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div align=middle><video src='data:video/mp4;base64,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' controls>Sorry, seems like your browser doesn't support HTML5 audio/video</video></div>"
      ],
      "text/plain": [
       "<moviepy.video.io.html_tools.HTML2 object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_kl.visualize_best()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\""
  },
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
