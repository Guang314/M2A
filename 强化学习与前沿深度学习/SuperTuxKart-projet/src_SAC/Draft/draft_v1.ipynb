{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from easypip import easyimport\n",
    "except ModuleNotFoundError:\n",
    "    from subprocess import run\n",
    "\n",
    "    assert (\n",
    "        run([\"pip\", \"install\", \"easypip\"]).returncode == 0\n",
    "    ), \"Could not install easypip\"\n",
    "    from easypip import easyimport\n",
    "\n",
    "easyimport(\"swig\")\n",
    "easyimport(\"bbrl_utils>=0.5\").setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "import gymnasium as gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystk2_gymnasium import AgentSpec\n",
    "from functools import partial\n",
    "from bbrl.agents.gymnasium import ParallelGymAgent, make_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env, option: int):\n",
    "        super().__init__(env)\n",
    "        self.option = option\n",
    "\n",
    "    def action(self, action):\n",
    "        # We do nothing here\n",
    "        return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 只保留连续 Observation 的 Wrapper\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "from pystk2_gymnasium.definitions import ActionObservationWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 Wrapper 删除 observation space 的 离散特征\n",
    "class OnlyContinousObservationWrapper(ActionObservationWrapper):\n",
    "    \"\"\"Removes discrete features from the observation space.\"\"\"\n",
    "    \n",
    "    def __init__(self, env: gym.Env, **kwargs):\n",
    "        super().__init__(env, **kwargs)\n",
    "        \n",
    "        # 过滤掉离散特征，只保留非离散特征\n",
    "        self._observation_space = env.observation_space['continuous']\n",
    "\n",
    "    def observation(self, observation: Dict):\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: The base environment name\n",
    "env_name = \"supertuxkart/flattened_continuous_actions-v0\"\n",
    "\n",
    "#: Player name\n",
    "player_name = \"Example\"\n",
    "\n",
    "def get_wrappers() -> List[Callable[[gym.Env], gym.Wrapper]]:\n",
    "    \"\"\"Returns a list of additional wrappers to be applied to the base\n",
    "    environment\"\"\"\n",
    "    return [\n",
    "        # Example of a custom wrapper\n",
    "        # lambda env: MyWrapper(env, option=\"1\"), \n",
    "        lambda env: OnlyContinousObservationWrapper(env),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space : \n",
      " Box([ 0. -1.], 1.0, (2,), float32)\n",
      "\n",
      "act_size : \n",
      " 2\n",
      "\n",
      "observation_space : \n",
      " Box([  0. -inf -inf -inf -inf -inf   0. -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf  -1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0. -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf   0.   0.   0.\n",
      "   0.   0.   0.   0. -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1. inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf], (91,), float32)\n",
      "\n",
      "obs_size : \n",
      " 91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "The path /dev/dri/ cannot be opened or is not available\n",
      "The path /dev/dri/ cannot be opened or is not available\n",
      "Unable to initialize SDL!: No available video device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: XDG_RUNTIME_DIR not set in the environment.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Setup the environment\n",
    "    make_stkenv = partial(\n",
    "        make_env,\n",
    "        env_name,\n",
    "        wrappers=get_wrappers(),\n",
    "        render_mode=None,\n",
    "        autoreset=True,\n",
    "        agent=AgentSpec(use_ai=False, name=player_name),\n",
    "    )\n",
    "\n",
    "    env_agent = ParallelGymAgent(make_stkenv, 1)\n",
    "    # env_agent = OnlyContinousObservationWrapper(env_agent)\n",
    "\n",
    "    env = env_agent.envs[0]\n",
    "\n",
    "    print('action_space : \\n', env.action_space)              # action_space 只有 discrete空间\n",
    "    print('\\nact_size : \\n', env.action_space.shape[0])\n",
    "\n",
    "    print('\\nobservation_space : \\n', env.observation_space)    # observation_space 有 continuous空间 和 discrete空间\n",
    "    print('\\nobs_size : \\n', env.observation_space.shape[0])\n",
    "\n",
    "    # print('\\n(continuous) observation_space : \\n', env.observation_space['continuous'])\n",
    "    # print('\\n(continuous) obs_size : \\n', env.observation_space['continuous'].shape[0])\n",
    "\n",
    "    # print('\\n(discrete) observation_space : \\n', env.observation_space['discrete'])\n",
    "    # print('\\n(discrete) obs_size : \\n', env.observation_space['discrete'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chen_guanyu/deepdac/lib/python3.10/site-packages/bbrl_utils/notebook.py:46: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm  # noqa: F401\n",
      "error: XDG_RUNTIME_DIR not set in the environment.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from easypip import easyimport\n",
    "except ModuleNotFoundError:\n",
    "    from subprocess import run\n",
    "\n",
    "    assert (\n",
    "        run([\"pip\", \"install\", \"easypip\"]).returncode == 0\n",
    "    ), \"Could not install easypip\"\n",
    "    from easypip import easyimport\n",
    "\n",
    "easyimport(\"swig\")\n",
    "easyimport(\"bbrl_utils>=0.5\").setup()\n",
    "\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from bbrl.workspace import Workspace\n",
    "from bbrl.agents import Agent, Agents, TemporalAgent, KWAgentWrapper\n",
    "from bbrl_utils.algorithms import EpochBasedAlgo\n",
    "from bbrl_utils.nn import build_mlp, setup_optimizer, soft_update_params\n",
    "from bbrl_utils.notebook import setup_tensorboard\n",
    "from omegaconf import OmegaConf\n",
    "from torch.distributions import (\n",
    "    Normal,\n",
    "    Independent,\n",
    "    TransformedDistribution,\n",
    "    TanhTransform,\n",
    ")\n",
    "import bbrl_gymnasium  # noqa: F401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib backend: inline\n",
      "\n",
      "action_space : \n",
      " Box(-1.0, 1.0, (1,), float64)\n",
      "\n",
      "act_size : \n",
      " 1\n",
      "\n",
      "observation_space : \n",
      " Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "\n",
      "obs_size : \n",
      " 4\n"
     ]
    }
   ],
   "source": [
    "make_CPCenv = partial(\n",
    "    make_env,\n",
    "    \"CartPoleContinuous-v1\"\n",
    ")\n",
    "\n",
    "env_agent_1 = ParallelGymAgent(make_CPCenv, 1)\n",
    "env_1 = env_agent_1.envs[0]\n",
    "\n",
    "print('\\naction_space : \\n', env_1.action_space)\n",
    "print('\\nact_size : \\n', env_1.action_space.shape[0])\n",
    "print('\\nobservation_space : \\n', env_1.observation_space)\n",
    "print('\\nobs_size : \\n', env_1.observation_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space :  Dict('acceleration': Box(0.0, 1.0, (1,), float32), 'brake': Discrete(2), 'drift': Discrete(2), 'fire': Discrete(2), 'nitro': Discrete(2), 'rescue': Discrete(2), 'steer': Box(-1.0, 1.0, (1,), float32)) \n",
      "\n",
      "observation_space :  Dict('attachment': Discrete(10), 'attachment_time_left': Box(0.0, inf, (1,), float32), 'center_path': Box(-inf, inf, (3,), float32), 'center_path_distance': Box(-inf, inf, (1,), float32), 'distance_down_track': Box(-inf, inf, (1,), float32), 'energy': Box(0.0, inf, (1,), float32), 'front': Box(-inf, inf, (3,), float32), 'items_position': Sequence(Box(-inf, inf, (3,), float32), stack=False), 'items_type': Sequence(Discrete(7), stack=False), 'jumping': Discrete(2), 'karts_position': Sequence(Box(-inf, inf, (3,), float32), stack=False), 'max_steer_angle': Box(-1.0, 1.0, (1,), float32), 'paths_distance': Sequence(Box(0.0, inf, (2,), float32), stack=False), 'paths_end': Sequence(Box(-inf, inf, (3,), float32), stack=False), 'paths_start': Sequence(Box(-inf, inf, (3,), float32), stack=False), 'paths_width': Sequence(Box(0.0, inf, (1,), float32), stack=False), 'powerup': Discrete(11), 'shield_time': Box(0.0, inf, (1,), float32), 'skeed_factor': Box(0.0, inf, (1,), float32), 'velocity': Box(-inf, inf, (3,), float32)) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..:: Antarctica Rendering Engine 2.0 ::..\n",
      "The path /dev/dri/ cannot be opened or is not available\n",
      "The path /dev/dri/ cannot be opened or is not available\n",
      "Unable to initialize SDL!: No available video device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: XDG_RUNTIME_DIR not set in the environment.\n"
     ]
    }
   ],
   "source": [
    "make_stkenv_full = partial(\n",
    "    make_env,\n",
    "    \"supertuxkart/full-v0\"\n",
    ")\n",
    "\n",
    "env_agent_2 = ParallelGymAgent(make_stkenv_full, 1)\n",
    "env_2 = env_agent_2.envs[0]\n",
    "\n",
    "print('action_space : ', env_2.action_space, '\\n')\n",
    "# print('act_size : ', env_2.action_space.shape[0], '\\n')\n",
    "print('observation_space : ', env_2.observation_space, '\\n')\n",
    "# print('obs_size : ', env_2.observation_space.shape[0], '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
