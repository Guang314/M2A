{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f517662-3db0-4434-ac10-2f9a41918719",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc328c3-511f-48c5-9cb8-4a7a243cb86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628f0063-0692-4637-a34f-d68fd4aceef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph(movies_fn, ratings_fn,min_rating=5, min_weight=10):\n",
    "    \"\"\" Construit le graphe des films:\n",
    "    * movies_fn : movies.csv\n",
    "    * ratings_fn : ratings.csv\n",
    "    * min_rating : seuil minimal du score pour lier un utilisateur à un film\n",
    "    * min_weight : seuil minimal du poids d'une arête pour la garder dans le graphe\n",
    "    \"\"\"\n",
    "    movies = pd.read_csv(movies_fn)\n",
    "    ratings = pd.read_csv(ratings_fn)\n",
    "\n",
    "    rated_movies = ratings[ratings.rating >=min_rating]\n",
    "    grouped_movies = rated_movies[['userId','movieId']].groupby('userId').agg(list)\n",
    "    pair_freq = defaultdict(int)\n",
    "    item_freq = defaultdict(int)\n",
    "\n",
    "    for lst_movies in tqdm(grouped_movies['movieId']):\n",
    "        pairs = combinations(sorted(lst_movies),2)\n",
    "        for i in lst_movies:\n",
    "            item_freq[i] += 1\n",
    "        for (i,j) in pairs:\n",
    "            pair_freq[(i,j)] += 1\n",
    "\n",
    "    movies_graph = nx.Graph()\n",
    "    log_total = math.log(sum(item_freq.values()))\n",
    "    # Pointwise Mutual Information : pmi(x,y) = log p(x,y)/(p(x)p(y)) = log (p(x,y)) - log(p(x)) -log(p(y))\n",
    "    for (i,j),f in pair_freq.items():\n",
    "        pmi = f*(math.log(f) - math.log(item_freq[i]) - math.log(item_freq[j]) + log_total)\n",
    "        if pmi >= min_weight:\n",
    "            movies_graph.add_edge(i,j,weight=pmi)\n",
    "\n",
    "    return movies_graph, movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb04cc2-1c1f-48f9-a7fb-242c85c463b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(graph, num_walks=5, num_steps=10, p=1, q=1):\n",
    "    \"\"\"\"\n",
    "        Construit un ensemble de chemins dans le graphe par marche aléatoire biaisée :\n",
    "        * graph : graphe\n",
    "        * num_walks: nombre de chemins par noeud\n",
    "        * num_step : longueur des chemins\n",
    "        * p : plus p est grand, plus l'exploration est incitée, p  petit -> plus il y a des retours en arriere\n",
    "        * q : plus q est grand, plus la marche reste localisée, q petit -> s'écarte des noeuds explorés\n",
    "    \"\"\"\n",
    "    def next_step(previous, current):\n",
    "        def get_pq(n):\n",
    "            if n == current: return p\n",
    "            if graph.has_edge(n,previous): return 1\n",
    "            return q\n",
    "        weights = [w['weight']/get_pq(n) for n,w in graph[current].items()]\n",
    "        return random.choices(list(graph[current]),weights=weights)[0]\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for walk_iter in range((num_walks)):\n",
    "        for node in tqdm(nodes):\n",
    "            walk = [node]\n",
    "            cur_node = node\n",
    "            prev_node = None\n",
    "            for step  in range(num_steps):\n",
    "                next_node = next_step(prev_node,cur_node)\n",
    "                walk.append(next_node)\n",
    "                prev_node = cur_node\n",
    "                cur_node = next_node\n",
    "            walks.append(walk)\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74baf742-8e32-4ba2-a352-3cbeb6c5281f",
   "metadata": {},
   "source": [
    "## TP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df03c58f-8265-4428-a826-8161c43662b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 11:07:28.579753: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736244449.020604    7627 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736244449.145912    7627 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-07 11:07:30.223625: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# from utils import random_walk,construct_graph\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f76ee-18b3-4ad6-bf27-7707cda9f5af",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4be9ba4-8900-4cee-91a9-c1290f3244cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "\n",
    "    def __init__(self, graph, walks, nodes2id):\n",
    "        self.graph = graph\n",
    "        self.walks = walks\n",
    "        self.nodes2id = nodes2id\n",
    "\n",
    "        self.positive_neighbors = {node: list(graph.neighbors(node)) for node in graph.nodes()}\n",
    "        self.all_nodes = list(graph.nodes())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_nodes)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Randomly select a anchor node\n",
    "        walk = self.walks[index]\n",
    "        anchor = random.choice(walk)\n",
    "\n",
    "        # Positive sample: a neighbor of the anchor\n",
    "        positive = random.choice(self.positive_neighbors[anchor])\n",
    "\n",
    "        # Neigative sample: a node not connected to the anchor node\n",
    "        while True:\n",
    "            negative = random.choice(self.all_nodes)\n",
    "            if not self.graph.has_edge(anchor, negative):\n",
    "                break\n",
    "\n",
    "        # Convert nodes to indices\n",
    "        anchor_idx = self.nodes2id[anchor]\n",
    "        positive_idx = self.nodes2id[positive]\n",
    "        negative_idx = self.nodes2id[negative]\n",
    "\n",
    "        return anchor_idx, positive_idx, negative_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b82ff5-a688-429a-b3b0-b108ef20afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeEmbeddingModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_nodes, embedding_dim):\n",
    "        super(NodeEmbeddingModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_nodes, embedding_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, nodes):\n",
    "        x = self.embeddings(nodes)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b90cdff-cc1f-4996-85aa-26edab9d6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_triplet_loss_with_visualization(model, dataloader, optimizer, criterion, id2title, num_epochs=10, log_dir='./runs'):\n",
    "\n",
    "    # 初始化 SummaryWriter\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for anchor, positive, negative in dataloader:\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "            # Get embeddings\n",
    "            anchor_emb = model(anchor)\n",
    "            positive_emb = model(positive)\n",
    "            negative_emb = model(negative)\n",
    "\n",
    "            # Triplet loss\n",
    "            loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        logging.info(f\"Epoch {epoch+1}/{num_epochs}, Loss = {epoch_loss:.4f}\")\n",
    "\n",
    "    # 每 5 个 epoch 可视化一次嵌入到 TensorBoard\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.eval()\n",
    "        embeddings = model.embeddings.weight.detach().cpu().numpy()\n",
    "        writer.add_embedding(\n",
    "            torch.tensor(embeddings), metadata=id2title, tag=f\"Epoch {epoch+1}\"\n",
    "        )\n",
    "        model.train()\n",
    "\n",
    "    writer.close()\n",
    "    logging.info(\"TensorBoard embeddings logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca9cf11-0c46-4436-8965-5c186e3b60f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Constructing graph\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 573/573 [00:00<00:00, 4979.32it/s]\n",
      "INFO:root:Sampling walks\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1405/1405 [00:01<00:00, 936.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1405/1405 [00:01<00:00, 933.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1405/1405 [00:01<00:00, 911.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1405/1405 [00:01<00:00, 929.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1405/1405 [00:01<00:00, 926.99it/s]\n",
      "INFO:root:Training loss with TensorBoard visualization\n",
      "INFO:root:Epoch 1/10, Loss = 43.0571\n",
      "INFO:root:Epoch 2/10, Loss = 39.9444\n",
      "INFO:root:Epoch 3/10, Loss = 35.5263\n",
      "INFO:root:Epoch 4/10, Loss = 33.0590\n",
      "INFO:root:Epoch 5/10, Loss = 31.1687\n",
      "INFO:root:Epoch 6/10, Loss = 29.0374\n",
      "INFO:root:Epoch 7/10, Loss = 29.3978\n",
      "INFO:root:Epoch 8/10, Loss = 27.0288\n",
      "INFO:root:Epoch 9/10, Loss = 27.9311\n",
      "INFO:root:Epoch 10/10, Loss = 25.5833\n",
      "INFO:root:TensorBoard embeddings logged.\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    PATH = \"data/ml-latest-small/\"\n",
    "    logging.info(\"Constructing graph\")\n",
    "    movies_graph, movies = construct_graph(PATH + \"movies.csv\", PATH + \"ratings.csv\")    # 构建 图\n",
    "    logging.info(\"Sampling walks\")\n",
    "    walks = random_walk(movies_graph,5,10,1,1)    # 随机游走\n",
    "    nodes2id = dict(zip(movies_graph.nodes(),range(len(movies_graph.nodes()))))\n",
    "    id2nodes = list(movies_graph.nodes())\n",
    "    id2title = [movies[movies.movieId==idx].iloc[0].title for idx in id2nodes]\n",
    "    ##  TODO: \n",
    "\n",
    "    dataset = TripletDataset(movies_graph, walks, nodes2id)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    num_nodes = len(nodes2id)\n",
    "    embedding_dim = 64\n",
    "    model = NodeEmbeddingModel(num_nodes, embedding_dim).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.TripletMarginLoss(margin = 1.0)\n",
    "\n",
    "    logging.info(\"Training loss with TensorBoard visualization\")\n",
    "    train_triplet_loss_with_visualization(\n",
    "        model, dataloader, optimizer, criterion, id2title, num_epochs=10, log_dir=\"./runs\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
